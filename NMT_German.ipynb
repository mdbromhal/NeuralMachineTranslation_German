{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Using Neural Machine Translation to Translate Between German & English"
      ],
      "metadata": {
        "id": "GjRwCxMvhdYY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "aRB0frWM9myS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading and opening the file\n",
        "with open(\"/content/drive/MyDrive/6 Spring 2024/CSC402/Chapter16/Neural Machine Translation/deu.txt\") as f:\n",
        "  dict_text = f.read()"
      ],
      "metadata": {
        "id": "G9auun4D4nRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict_text[:80] # Showing the first 80 characters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "9ZWq_JuD5E_p",
        "outputId": "4a5d7b0e-f3aa-4fd0-9c9c-86af39e6cd39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Go.\\tGeh.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #8597805 (R'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Code implemented from LofiAI to remove unnecessary text from file\n",
        "def remove_text(input_file, output_file, start_char, end_char):\n",
        "    with open(input_file, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "\n",
        "    with open(output_file, 'w') as file:\n",
        "        for line in lines:\n",
        "            start_index = line.find(start_char)\n",
        "            end_index = line.find(end_char, start_index + 1)\n",
        "            if start_index != -1 and end_index != -1:\n",
        "                updated_line = line[:start_index] + line[end_index + 1:]\n",
        "                file.write(updated_line+ '\\n')\n",
        "            else:\n",
        "                file.write(line)"
      ],
      "metadata": {
        "id": "YzTNIiHc8Ee0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Code taken from LofiAI, calling function above\n",
        "input_file = '/content/drive/MyDrive/6 Spring 2024/CSC402/Chapter16/Neural Machine Translation/deu.txt'\n",
        "output_file = '/content/drive/MyDrive/6 Spring 2024/CSC402/Chapter16/Neural Machine Translation/clean_du.txt'\n",
        "start_char = '\\tCC-BY'\n",
        "end_char = '\\n'\n",
        "remove_text(input_file, output_file, start_char, end_char)"
      ],
      "metadata": {
        "id": "FzGaoQ2K8Utd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Opening and reading the clean file\n",
        "with open('/content/drive/MyDrive/6 Spring 2024/CSC402/Chapter16/Neural Machine Translation/clean_du.txt') as f:\n",
        "  du = f.read()"
      ],
      "metadata": {
        "id": "KKYwqcFu8k0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "du[:80] # Showing the first 80 characters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "DVPAbMrp8vCw",
        "outputId": "6902e053-97d7-4e22-c872-6fbd44fb889e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Go.\\tGeh.\\nHi.\\tHallo!\\nHi.\\tGrüß Gott!\\nRun!\\tLauf!\\nRun.\\tLauf!\\nWow!\\tPotzdonner!\\nWow!\\tD'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Identifying eng-du pairs and splitting on the tab\n",
        "pairs = [line.split(\"\\t\") for line in du.splitlines()]\n",
        "np.random.seed(42)  # extra code – ensures reproducibility on CPU\n",
        "\n",
        "# Shuffling the pairs to help training\n",
        "np.random.shuffle(pairs)\n",
        "\n",
        "# Zipping the pairs together so the eng phrase is associated with the du phrase\n",
        "sentences_en, sentences_du = zip(*pairs)  # separates the pairs into 2 lists"
      ],
      "metadata": {
        "id": "lrOIbJ4J9C1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing the first three shuffled pairs\n",
        "for i in range(3):\n",
        "    print(sentences_en[i], \"=>\", sentences_du[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eP9Vsc2x9HEI",
        "outputId": "54032204-40b7-490f-98b1-0c4b2b2b38bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "He was lying on the couch. => Er lag auf dem Sofa.\n",
            "All generalizations are false, including this one. => Alle Verallgemeinerungen sind falsch, einschließlich dieser hier.\n",
            "She dyed her white skirt red. => Sie färbte ihren weißen Rock rot.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the vocab_size and max_length parameters to vectorize each english and german word\n",
        "vocab_size = 1000\n",
        "max_length = 50\n",
        "\n",
        "# Vectorizing the english and german words\n",
        "text_vec_layer_en = tf.keras.layers.TextVectorization(\n",
        "    vocab_size, output_sequence_length=max_length)\n",
        "text_vec_layer_du = tf.keras.layers.TextVectorization(\n",
        "    vocab_size, output_sequence_length=max_length)\n",
        "\n",
        "# Explanation from Colab AI:\n",
        "# adapt method updates internal parameters of text_vec_layer objects\n",
        "# Better represents input sentences\n",
        "text_vec_layer_en.adapt(sentences_en) # Vectorized english words adapted to english sentences in sentences_en\n",
        "# Vectorized german words adapted to german sentences\n",
        "# Preprocessed with start and end tokens\n",
        "text_vec_layer_du.adapt([f\"startofseq {s} endofseq\" for s in sentences_du])"
      ],
      "metadata": {
        "id": "gGzfPbRYXjpJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_vec_layer_en.get_vocabulary()[:10] # Printing the first ten english vocab words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8aV7icHXx2l",
        "outputId": "48bcd974-f55a-42be-e27d-74f5cfb8bbe8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', '[UNK]', 'tom', 'to', 'you', 'the', 'i', 'a', 'is', 'that']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_vec_layer_du.get_vocabulary()[:10] # Printing first ten german vocab words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7pYBLp-Xz8_",
        "outputId": "41e6f912-a118-44f9-8ab4-e830472f1890"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " '[UNK]',\n",
              " 'startofseq',\n",
              " 'endofseq',\n",
              " 'ich',\n",
              " 'tom',\n",
              " 'nicht',\n",
              " 'ist',\n",
              " 'das',\n",
              " 'sie']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the training and validation sequences\n",
        "X_train = tf.constant(sentences_en[:100_000])\n",
        "X_valid = tf.constant(sentences_en[100_000:])\n",
        "X_train_dec = tf.constant([f\"startofseq {s}\" for s in sentences_du[:100_000]])\n",
        "X_valid_dec = tf.constant([f\"startofseq {s}\" for s in sentences_du[100_000:]])\n",
        "Y_train = text_vec_layer_du([f\"{s} endofseq\" for s in sentences_du[:100_000]])\n",
        "Y_valid = text_vec_layer_du([f\"{s} endofseq\" for s in sentences_du[100_000:]])"
      ],
      "metadata": {
        "id": "bHso9wzpX3bY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)  # extra code – ensures reproducibility on CPU\n",
        "# Initializing the encoder and decoder inputs as an empty string list\n",
        "encoder_inputs = tf.keras.layers.Input(shape=[], dtype=tf.string)\n",
        "decoder_inputs = tf.keras.layers.Input(shape=[], dtype=tf.string)"
      ],
      "metadata": {
        "id": "LgMD7nTTYF6T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed_size = 128\n",
        "# Setting the encoder id's to english vectorized inputs\n",
        "encoder_input_ids = text_vec_layer_en(encoder_inputs)\n",
        "\n",
        "# Setting decoder id's to german vectorized inputs\n",
        "decoder_input_ids = text_vec_layer_du(decoder_inputs)\n",
        "\n",
        "# Defining the encoder embedding layer\n",
        "encoder_embedding_layer = tf.keras.layers.Embedding(vocab_size, embed_size,\n",
        "                                                    mask_zero=True)\n",
        "\n",
        "# Defining the decoder embedding layer\n",
        "decoder_embedding_layer = tf.keras.layers.Embedding(vocab_size, embed_size,\n",
        "                                                    mask_zero=True)\n",
        "\n",
        "# Defining the embeddings to use in the layers\n",
        "encoder_embeddings = encoder_embedding_layer(encoder_input_ids)\n",
        "decoder_embeddings = decoder_embedding_layer(decoder_input_ids)"
      ],
      "metadata": {
        "id": "KxzOrH52YJoO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the encoder as an LSTM model\n",
        "encoder = tf.keras.layers.LSTM(512, return_state=True)\n",
        "encoder_outputs, *encoder_state = encoder(encoder_embeddings)"
      ],
      "metadata": {
        "id": "ojc2Nc6BYMmb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the decoder as an LSTM model\n",
        "decoder = tf.keras.layers.LSTM(512, return_sequences=True)\n",
        "decoder_outputs = decoder(decoder_embeddings, initial_state=encoder_state)"
      ],
      "metadata": {
        "id": "B6yV-GU6YPPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using Dense layers\n",
        "output_layer = tf.keras.layers.Dense(vocab_size, activation=\"softmax\")\n",
        "\n",
        "Y_proba = output_layer(decoder_outputs)"
      ],
      "metadata": {
        "id": "-KrnTvQfYRQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Model(inputs=[encoder_inputs, decoder_inputs],\n",
        "                       outputs=[Y_proba])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# Training the model\n",
        "model.fit((X_train, X_train_dec), Y_train, epochs=1,\n",
        "          validation_data=((X_valid, X_valid_dec), Y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8zRZqYyYTun",
        "outputId": "3cece7f2-ba46-44ef-ed63-b1ac0cc2b7df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3125/3125 [==============================] - 6329s 2s/step - loss: 2.9183 - accuracy: 0.4326 - val_loss: 2.2232 - val_accuracy: 0.5229\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7bf2f148a680>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Takes the encoder input and decodes the sentence - translates it\n",
        "def translate(sentence_en):\n",
        "    translation = \"\"\n",
        "    for word_idx in range(max_length):\n",
        "        X = np.array([sentence_en])  # encoder input\n",
        "        X_dec = np.array([\"startofseq \" + translation])  # decoder input\n",
        "        y_proba = model.predict((X, X_dec))[0, word_idx]  # last token's probas\n",
        "        predicted_word_id = np.argmax(y_proba)\n",
        "        predicted_word = text_vec_layer_du.get_vocabulary()[predicted_word_id]\n",
        "        if predicted_word == \"endofseq\":\n",
        "            break\n",
        "        translation += \" \" + predicted_word\n",
        "    return translation.strip()"
      ],
      "metadata": {
        "id": "9q2BicatYWMf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing the translator"
      ],
      "metadata": {
        "id": "ERC6iNt8F_ta"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "translate(\"I like soccer\")"
      ],
      "metadata": {
        "id": "VjXhbaciYnPA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "outputId": "cb3f3bd6-c117-4c7f-835f-2bee595ec686"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 33s 33s/step\n",
            "1/1 [==============================] - 0s 79ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ich mag [UNK]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Google translate: Ich mag Fußball"
      ],
      "metadata": {
        "id": "dmAmnrQIca97"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "translate(\"Hello, I am a student!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "bIrTQ8lzcdvx",
        "outputId": "1fc9abef-7e3d-4bfd-c26b-7e67dad26d91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 76ms/step\n",
            "1/1 [==============================] - 0s 75ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 75ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[UNK] ist ein [UNK]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Google translate: Hallo, ich bin Student!"
      ],
      "metadata": {
        "id": "192y_9Prcpep"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "translate(\"From the pomogranite in thine hand, Persephonie, thou shalt reign.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "id": "KtWUmi60cow0",
        "outputId": "d7172a2a-91c9-4465-b63c-3f7851153531"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 76ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 83ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[UNK] die [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Google translate: Aus dem Granatapfel in deiner Hand, Persephonie, sollst du herrschen."
      ],
      "metadata": {
        "id": "ugbC4hjYc9EL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Improvements in future versions\n",
        "- Need to take out unknown and check length of characters -- see if matches vocab_size to vectorization\n",
        "- Translation is not very good, so maybe this will help\n",
        "- Do more epochs (use a better runtime)\n",
        "  - I wasn't able to connect to a better runtime, so 1 epoch took 1 hour and 30 minutes, which is why I only did one\n",
        "  - With more epochs, I would hope the translations would improve."
      ],
      "metadata": {
        "id": "KN51gV2SGGEd"
      }
    }
  ]
}